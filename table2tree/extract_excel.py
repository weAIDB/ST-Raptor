import re
import os
import glob
import json
import openpyxl
# import openpyxl.workbook
# import openpyxl.workbook.properties
# import openpyxl.worksheet
# import openpyxl.worksheet.worksheet
import requests

import pandas as pd
import numpy as np
import tqdm as tqdm
from loguru import logger

from utils.api_utils import *
from utils.sheet_utils import *
from utils.split_utils import *
from utils.attr_extraction import *
from utils.constants import *


def logAuto(info, flag=True):
    if flag:
        logger.info(info)


def match_min_table_structure(sheet):
    """åŒ¹é…æœ€å°ç»“æ„ï¼Œå³ä¸€ä¸ªæˆ–ä¸¤ä¸ªå•å…ƒæ ¼çš„æ—¶å€™"""
    nrows = sheet.max_row
    ncols = sheet.max_column

    # if nrows < 1 or ncols < 1 or nrows > 2 or ncols > 2 or (nrows == 2 and ncols == 2):
    # return None
    # if nrows == 1 and ncols == 1:
    # return {sheet.cell(row=1, column=1).value : None}

    first_cell = sheet.cell(row=1, column=1)
    _, _, x2, y2 = get_merge_cell_size(sheet, first_cell.coordinate)

    if x2 == nrows and y2 == ncols:
        return {get_merge_cell_value(sheet, first_cell.coordinate): None}
    if x2 == nrows:
        second_cell = sheet.cell(row=1, column=y2 + 1)
        _, _, xx2, yy2 = get_merge_cell_size(sheet, second_cell.coordinate)
        if yy2 == ncols:
            return {
                get_merge_cell_value(
                    sheet, first_cell.coordinate
                ): get_merge_cell_value(sheet, second_cell.coordinate)
            }
    if y2 == ncols:
        second_cell = sheet.cell(row=x2 + 1, column=1)
        _, _, xx2, yy2 = get_merge_cell_size(sheet, second_cell.coordinate)
        if xx2 == nrows:
            return {
                get_merge_cell_value(
                    sheet, first_cell.coordinate
                ): get_merge_cell_value(sheet, second_cell.coordinate)
            }


def match_attr(sheet, pos_list):
    return_dict = {}

    nrows = sheet.max_row
    ncols = sheet.max_column

    x = 1
    while x <= nrows:
        y = 1
        while y <= ncols:
            cell = sheet.cell(row=x, column=y)
            x1, y1, x2, y2 = get_merge_cell_size(sheet, cell.coordinate)
            if in_pos_list(x, y, pos_list) is not None:  # æ˜¯Schema
                key = get_merge_cell_value(sheet, cell.coordinate)
                if in_pos_list(x, y2 + 1, pos_list) is None:  # è‹¥å³è¾¹ä¸æ˜¯Schema
                    return_dict[key] = get_merge_cell_value(
                        sheet, sheet.cell(row=x, column=y2 + 1).coordinate
                    )
                if in_pos_list(x2 + 1, y, pos_list) is None:  # è‹¥ä¸‹é¢ä¸æ˜¯Schema
                    if key not in return_dict or (
                        key in return_dict
                        and (return_dict[key] is None or return_dict[key] == "")
                    ):
                        return_dict[key] = get_merge_cell_value(
                            sheet, sheet.cell(row=x2 + 1, column=y).coordinate
                        )
            y += y2 - y1 + 1
        x += 1

    return return_dict


def match_list_column(schema, sheet):
    """å±æ€§ååœ¨è¡¨æ ¼å·¦ä¾§çš„æƒ…å†µä¸‹æå–å­åŠç»“æ„åŒ–è¡¨æ ¼"""
    # Step1 è·å–Schema
    # æ‰¾åˆ°ç¬¬ä¸€è¡Œä¸­é«˜åº¦æœ€é«˜çš„å•å…ƒæ ¼ï¼Œå³ç¡®å®šæ•´ä¸ªSchemaè¡Œåˆå¹¶äº†å¤šå°‘è¡Œ
    nrows = sheet.max_row
    ncols = sheet.max_column

    # Step2 æå–Schema
    schema = extract_schema_column(schema)
    flattenned_schema = flatten_schema(schema)  # å±•å¹³Schema

    # Step3 é¢„å¤„ç†åˆ‡åˆ†è¡¨æ ¼ï¼Œä¿è¯ä»å·¦å‘å³ç²’åº¦ä¸å¢ï¼Œå¹¶è®°å½•åˆ‡åˆ†çš„å®ä½“å…³ç³»
    content = sheet
    col = 1
    while col <= ncols:
        x1, y1, x2, y2 = get_merge_cell_size(
            content, content.cell(row=1, column=col).coordinate
        )
        max_width = y2 - y1 + 1
        row = x2 + 1
        while row <= nrows:
            cell = content.cell(row=row, column=col)
            x1, y1, x2, y2 = get_merge_cell_size(content, cell.coordinate)
            width = y2 - y1 + 1
            if width > max_width:  # split
                value = content.cell(row=x1, column=y1).value
                content.unmerge_cells(get_coordinate_by_cell_pos(x1, y1, x2, y2))
                content[
                    get_coordinate_by_cell_pos(x1, y1 + max_width, x1, y1 + max_width)
                ] = value
                content.merge_cells(
                    get_coordinate_by_cell_pos(x1, y1, x2, y1 + max_width - 1)
                )
                content.merge_cells(
                    get_coordinate_by_cell_pos(x1, y1 + max_width, x2, y2)
                )
            row += x2 - x1 + 1
        col += max_width

    # Step4 å¼€å§‹é€’å½’çš„æŒ‰åˆ—åˆ‡åˆ†è¡¨æ ¼
    col_content = extract_columns(content)

    print(flattenned_schema, col_content)

    # Step5 æ„å»ºåµŒå¥—çš„å­—å…¸æ ¼å¼
    return_list, _ = schema_content_match(flattenned_schema, col_content)

    return return_list


def get_schema_height(sheet, direction):
    height = 1

    nrows = sheet.max_row
    ncols = sheet.max_column

    if direction == SCHEMA_TOP:
        for col in range(1, ncols + 1):
            _, _, x2, _ = get_merge_cell_size(
                sheet, sheet.cell(row=1, column=col).coordinate
            )
            height = max(height, x2)

    elif direction == SCHEMA_LEFT:
        for row in range(1, nrows + 1):
            _, _, _, y2 = get_merge_cell_size(
                sheet, sheet.cell(row=row, column=1).coordinate
            )
            height = max(height, y2)

    return height

def get_nrow_cells(sheet):
    n = 0
    
    nrows = sheet.max_row
    ncols = sheet.max_column
    
    for row in range(1, nrows + 1):
        col = 1
        cnt = 0
        while col <= ncols:
            cnt += 1            
            cell = sheet.cell(row=row, column=col)
            x1, y1, x2, y2 = get_merge_cell_size(sheet, cell.coordinate)
            col += (y2 - y1 + 1)
        n = max(n, cnt)
    return n

def get_ncol_cells(sheet):
    n = 0
    
    nrows = sheet.max_row
    ncols = sheet.max_column
    
    for col in range(1, ncols + 1):
        row = 1
        cnt = 0
        while row <= nrows:
            cnt += 1
            cell = sheet.cell(row=row, column=col)
            x1, y1, x2, y2 = get_merge_cell_size(sheet, cell.coordinate)
            row += (x2 - x1 + 1)
        n = max(n, cnt)
    
    return n

def preprocess_cell(value):

    value = str(value)
    # value = re.sub(r"\s+", "", value)  # å»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦

    return value


def preprocess_sheet(sheet):
    for row in sheet.iter_rows():
        for cell in row:
            if cell.value is not None:
                cell.value = preprocess_cell(cell.value)
    return sheet


def get_xlsx_sheet(file):
    wb = openpyxl.load_workbook(file, data_only=True)
    sheet = preprocess_sheet(wb.active)
    return sheet


def process_xlsx_vlm(file, get_json=False, log=False, cache=False):
    logAuto(f"process_xlsx_vlm() Start to Process File: {file}", log)
    wb = openpyxl.load_workbook(file, data_only=True)
    sheet = preprocess_sheet(wb.active)
    res = process_sheet_vlm(sheet, get_json=get_json, log=log, cache=cache)
    logAuto(f"process_xlsx_vlm() Process File Successfully: {file} ", log)
    return res

################################# Main #################################
def process_sheet_vlm(sheet,            # å¾…å¤„ç†çš„Excelå·¥ä½œç°¿æ ¼å¼çš„è¡¨æ ¼
                      get_json=False,   # è·å¾—VLM + Ruleè¯†åˆ«åçš„ä¸­é—´ç»“æœJSON
                      log=False,        # åœ¨æ§åˆ¶å°è¾“å‡ºæ—¥å¿—
                      log_file=None,    # æ—¥å¿—è¾“å‡ºæ–‡ä»¶
                      cache=False       # ä¿å­˜ä¸­é—´ç»“æœæ–‡ä»¶
                      ):
    
    # Step 1 preprocess
    delete_empty_columns(sheet)
    delete_empty_rows(sheet)

    nrows = sheet.max_row
    ncols = sheet.max_column

    nrow_cells = get_nrow_cells(sheet)
    ncol_cells = get_ncol_cells(sheet)

    if log_file is not None:    # Log
        with open(log_file, 'w') as file:
            file.write(f'{DELIMITER} è¿›å…¥ process_sheet_vlm() å‡½æ•° {DELIMITER}\n')
            file.write(f'è¡¨æ ¼è¡Œæ•°: {nrows} è¡¨æ ¼åˆ—æ•°: {ncols}\nè¡¨æ ¼æ¯è¡Œæœ€å¤šå‡ºç°çš„Cellæ•°: {nrow_cells} è¡¨æ ¼æ¯åˆ—æœ€å¤šå‡ºç°çš„Cellæ•°: {ncol_cells}\n')
    logAuto(f"å½“å‰è¡¨æ ¼ nrows: {nrows} ncols: {ncols}", log)

    # é€’å½’è¿”å›æ¡ä»¶ 1: åŒ¹é…åˆ°æœ€å°ç»“æ„å•å…ƒ
    res = match_min_table_structure(sheet)
    if res is not None:
        logAuto(f"åŒ¹é…åˆ°æœ€å°ç»“æ„å•å…ƒ: {res}", log)
        if log_file is not None:    # Log
            with open(log_file, 'w') as file:
                file.write(f'{DELIMITER} é€’å½’è¿”å›æ¡ä»¶: åŒ¹é…åˆ°æœ€å°ç»“æ„å•å…ƒ {DELIMITER}\n')
                file.write(f'æœ€å°ç»“æ„å•å…ƒ: {res}\n')
        return res

    # é€’å½’è¿”å›æ¡ä»¶ 2: è¡¨ä¸ºå°è¡¨
    if (nrow_cells < SMALL_TABLE_ROWS and ncol_cells < BIG_TABLE_COLUMNS) or (
        nrow_cells < BIG_TABLE_ROWS and ncol_cells < SMALL_TABLE_COLUMNS
    ):
        logAuto(f"è¡¨ä¸ºå°è¡¨ï¼Œä¸ºé¿å…å¹»è§‰ç›´æ¥è§£æ", log)
        res = vlm_get_json(sheet)
        if log_file is not None:    # Log
            with open(log_file, 'w') as file:
                file.write(f'{DELIMITER} é€’å½’è¿”å›æ¡ä»¶: è¡¨ä¸ºå°è¡¨ {DELIMITER}\n')
                file.write(f'VLMç›´æ¥è§£æç»“æœ: {res}\n')
        return res

    # Step 2 split merged entire
    sheet_dict = rowspan_entire(sheet)  # è·å¾—æ·±åº¦å¯èƒ½ä¸ä¸º1çš„sheet_dict
    if len(sheet_dict) == 1 and list(sheet_dict.keys())[0] == DEFAULT_TABLE_NAME:
        sheet_dict = colspan_entire(sheet)
    logAuto(f"è·¨è¡¨æ‹†è§£å‡º {len(sheet_dict)} ä¸ªå­è¡¨", log)
    logAuto(sheet_dict, log)
    if log_file is not None:    # Log
        with open(log_file, 'w') as file:
            file.write(f'{DELIMITER} æ•´è¡Œ/æ•´åˆ—åˆå¹¶å•å…ƒæ ¼æ‹†åˆ†ç»“æœ, keyä¸ºtableæ„æ€æ˜¯ä¸å­˜åœ¨æ•´è¡Œ/æ•´åˆ—åˆå¹¶ {DELIMITER}\n')
            file.write(f'{sheet_dict}\n')

    # Step 3 iterate each element
    for key, sheet in sheet_dict.items():

        if sheet is None:
            continue

        delete_empty_columns(sheet)
        delete_empty_rows(sheet)

        # Step 4 judge the direction of the schema

        # æ ¹æ®è¡¨æ ¼åˆå¹¶å•å…ƒæ ¼çš„ç²’åº¦å˜åŒ–æ¥åˆ¤æ–­Schemaæ–¹å‘
        # if granularity_decrease_col(sheet):
        #     granularity_directon_col = SCHEMA_TOP
        # else:
        #     granularity_directon_col = SCHEMA_FAIL
        # if granularity_decrease_row(sheet):
        #     granularity_directon_row = SCHEMA_LEFT
        # else:
        #     granularity_directon_row = SCHEMA_FAIL

        # å…¶æ¬¡ä½¿ç”¨VLMè¾…åŠ©åˆ¤æ–­
        print(f"ğŸ” VLM Schemaæ£€æµ‹å¼€å§‹: {key}")
        schema_vague = vlm_get_schema(sheet, save=cache)
        print(f"ğŸ” VLM Schemaæ£€æµ‹ç»“æŸ: {schema_vague}")
        pos_list, schema_list, pos2schema = schema_pos_match(
            sheet, schema_vague, enable_embedding=True
        )  # å°† vlm çš„è¾“å‡ºä¸è¡¨æ ¼å†…å®¹å¯¹åº”ï¼Œå¹¶è·å– schema çš„ä½ç½®
        direction = get_schema_direction_by_pos(sheet, pos_list)
        #direction = SCHEMA_TOP
        # direction = SCHEMA_TOP
        schema_height = get_schema_height(sheet, direction)
        d = "ä¸Šéƒ¨" if direction == SCHEMA_TOP else "å·¦ä¾§"
        logAuto(f"{key} çš„ Schema æ–¹å‘ä¸º {d}", log)
        logAuto(f"{key} çš„ Schema é«˜åº¦ä¸º {schema_height}", log)
        logAuto(f"{key} çš„ Schema ä¸º: {schema_list}", log)
        print(f"ğŸ“‹ Schemaæ–¹å‘åˆ¤æ–­: {direction}")
        # Step 5 æ ¹æ® schema æ–¹å‘æ‹†åˆ†è¡¨æ ¼, Schemaåœ¨å·¦è¾¹, ä¸Šä¸‹æ‹†åˆ†ä¸ºå¹¶åˆ—çš„å¤šä¸ªå­éƒ¨åˆ†; Schemaåœ¨ä¸Šé¢, å·¦å³æ‹†åˆ†ä¸ºå¹¶åˆ—çš„å¤šä¸ªå­éƒ¨åˆ†
        parallel_sheet = None
        if direction == SCHEMA_TOP:
            parallel_sheet = split_subtable_row(sheet)
            logAuto(
                f"{key} å­è¡¨æ ¹æ®ç²’åº¦å˜åŒ–æ‹†è§£ä¸ºäº† {len(parallel_sheet)} ä¸ªå­éƒ¨åˆ†", log
            )
        elif direction == SCHEMA_LEFT:
            # æ ¹æ®ç²’åº¦å˜åŒ–åˆ¤æ–­æ˜¯ä¸€ä¸ªç»“æ„åŒ–è¡¨æ ¼ï¼Œè¿˜æ˜¯ä¸€ä¸ªåŠç»“æ„åŒ–å­è¡¨
            schema, data_sheet = split_schema_column(sheet)
            if (
                granularity_decrease_row(data_sheet)
                and data_sheet.max_column / data_sheet.max_row > 2
            ):  # ç²’åº¦é€’å‡å¹¶ä¸”æ˜¯å®½è¡¨
                parallel_sheet = []
                sheet = transpose_sheet(sheet)
            else:
                parallel_sheet = split_subtable_each_row(sheet, schema_height)
                logAuto(
                    f"{key} å­è¡¨æ ¹æ®è¡Œæ•°æ‹†è§£ä¸ºäº† {len(parallel_sheet)} ä¸ªå­éƒ¨åˆ†", log
                )
        else:
            res = vlm_get_json(sheet, save=cache)
            sheet_dict[key] = res
            logAuto(f"{key} å­è¡¨æœªè¯†åˆ«Schemaæ–¹å‘, ä½¿ç”¨ VLM ç›´æ¥è§£æ, ç»“æœä¸º {res}", log)
            continue

        # Step 6 å¦‚æœsheetè¢«åˆ†ä¸ºäº†å¤šä¸ªå¹¶åˆ—çš„sheetï¼Œåˆ™åˆ†åˆ«é€’å½’å¤„ç†ï¼Œå¦åˆ™ç›´æ¥å¤„ç†
        if len(parallel_sheet) > 1:
            if isinstance(parallel_sheet, list):
                json_dict = {}
                subtable_cnt = 1
                print(f"ğŸ”„ é€’å½’å¤„ç†å­è¡¨ {index}")
                for index, subsheet in enumerate(parallel_sheet):
                    res = process_sheet_vlm(subsheet, get_json, log)
                    logAuto(f"subsheet {index} done", log)
                    if DEFAULT_TABLE_NAME in res:
                        res = res[DEFAULT_TABLE_NAME]
                        if isinstance(res, dict):
                            json_dict.update(res)
                        else:
                            json_dict[f"{DEFAULT_SUBTABLE_NAME}{subtable_cnt}"] = res
                            subtable_cnt += 1
                    else:
                        json_dict.update(res)
                sheet_dict[key] = json_dict
            elif isinstance(parallel_sheet, dict):
                json_dict = {}
                for name, sheet in parallel_sheet.items():
                    if isinstance(sheet, (str, int, float)) or sheet is None:
                        json_dict[name] = sheet
                    else:
                        res = process_sheet_vlm(sheet, get_json, log)  # a dict
                        if len(res) == 1 and DEFAULT_TABLE_NAME in res:
                            res = res[DEFAULT_TABLE_NAME]
                        if DEFAULT_SUBTABLE_NAME in name and isinstance(res, dict):
                            json_dict.update(res)
                        else:
                            json_dict[name] = res
                    logAuto(f"subsheet {name} done", log)
                sheet_dict[key] = json_dict
            continue

        # Step 7 ç›´æ¥å¤„ç†
        # Treat as List
        if get_json:
            try:
                schema_sheet, data_sheet = split_schema_row(sheet)
                res = match_list_column(schema_sheet, data_sheet)
            except Exception as e:
                import traceback
                traceback.print_exc()
                logAuto(f"Process List Exception {e}", log)
                res = vlm_get_json(sheet, save=cache)
            sheet_dict[key] = res

        # Step 7.1 å°è¯•æ ¹æ®åŒ¹é…åˆ°çš„Schemaï¼Œå†è¿›è¡Œæ‹†åˆ†ä¸ºå¤šä¸ªå¹¶åˆ—çš„è¡¨æ ¼
        # if direction == SCHEMA_TOP:
        #     try_sheet_list = split_subtable_by_schema(sheet, pos_list)
        #     pass
        # elif direction == SCHEMA_LEFT:
        #     pass

    return sheet_dict
